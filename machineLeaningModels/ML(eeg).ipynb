{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL FOR EEG NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAwake_train = pd.read_csv('Data/training_AData.txt', header=None, delim_whitespace=True)\n",
    "dfDrowsy_train = pd.read_csv('Data/training_DData.txt', header=None, delim_whitespace=True)\n",
    "dfAwake_test = pd.read_csv('Data/testing_AData.txt', header=None, delim_whitespace=True)\n",
    "dfDrowsy_test = pd.read_csv('Data/testing_DData.txt', header=None, delim_whitespace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Retrieved Data informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240000, 15)\n",
      "(3240000, 15)\n",
      "(1620000, 15)\n",
      "(1620000, 15)\n"
     ]
    }
   ],
   "source": [
    "print(dfAwake_train.shape)\n",
    "print(dfDrowsy_train.shape)\n",
    "print(dfAwake_test.shape)\n",
    "print(dfDrowsy_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Not Needed Columns Keeping EEG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAwake_train = dfAwake_train.drop(dfAwake_train.iloc[:,11:15],axis = 1)\n",
    "dfAwake_train = dfAwake_train.drop(dfAwake_train.iloc[:,0:3],axis = 1)\n",
    "dfDrowsy_train = dfDrowsy_train.drop(dfDrowsy_train.iloc[:,11:15],axis = 1)\n",
    "dfDrowsy_train = dfDrowsy_train.drop(dfDrowsy_train.iloc[:,0:3],axis = 1)\n",
    "dfAwake_test = dfAwake_test.drop(dfAwake_test.iloc[:,11:15],axis = 1)\n",
    "dfAwake_test = dfAwake_test.drop(dfAwake_test.iloc[:,0:3],axis = 1)\n",
    "dfDrowsy_test = dfDrowsy_test.drop(dfDrowsy_test.iloc[:,11:15],axis = 1)\n",
    "dfDrowsy_test = dfDrowsy_test.drop(dfDrowsy_test.iloc[:,0:3],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3240000, 8)\n",
      "(3240000, 8)\n",
      "(1620000, 8)\n",
      "(1620000, 8)\n"
     ]
    }
   ],
   "source": [
    "print(dfAwake_train.shape)\n",
    "print(dfDrowsy_train.shape)\n",
    "print(dfAwake_test.shape)\n",
    "print(dfDrowsy_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESHAPING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 900, 8)\n",
      "(3600, 900, 8)\n",
      "(1800, 900, 8)\n",
      "(1800, 900, 8)\n"
     ]
    }
   ],
   "source": [
    "dfAwake_train = dfAwake_train.to_numpy()\n",
    "dfDrowsy_train = dfDrowsy_train.to_numpy()\n",
    "dfAwake_train = dfAwake_train.reshape(3600,900,8)\n",
    "dfDrowsy_train = dfDrowsy_train.reshape(3600,900,8)\n",
    "dfAwake_test = dfAwake_test.to_numpy()\n",
    "dfDrowsy_test = dfDrowsy_test.to_numpy()\n",
    "dfAwake_test = dfAwake_test.reshape(1800,900,8)\n",
    "dfDrowsy_test = dfDrowsy_test.reshape(1800,900,8)\n",
    "print(dfAwake_train.shape)\n",
    "print(dfDrowsy_train.shape)\n",
    "print(dfAwake_test.shape)\n",
    "print(dfDrowsy_test.shape)\n",
    "# print(dfAwake.head)\n",
    "# print(dfDrowsy.head)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600,)\n",
      "(3600,)\n",
      "(1800,)\n",
      "(1800,)\n"
     ]
    }
   ],
   "source": [
    "dfAwake_trainLabels = np.zeros(3600)\n",
    "print(dfAwake_trainLabels.shape)\n",
    "dfDrowsy_trainLabels = np.ones(3600)\n",
    "print(dfDrowsy_trainLabels.shape)\n",
    "dfAwake_testLabels = np.zeros(1800)\n",
    "print(dfAwake_testLabels.shape)\n",
    "dfDrowsy_testLabels = np.ones(1800)\n",
    "print(dfDrowsy_testLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(dfAwake_trainLabels)\n",
    "print(dfDrowsy_trainLabels)\n",
    "print(dfAwake_testLabels)\n",
    "print(dfDrowsy_testLabels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Awake Data and Drowsy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 900, 8)\n",
      "(7200,)\n",
      "[[[1.       2.757393 1.724006 ... 3.274563 1.257075 0.776789]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  ...\n",
      "  [1.       0.62141  0.093751 ... 0.136937 0.070096 0.032042]\n",
      "  [1.       0.62141  0.093751 ... 0.136937 0.070096 0.032042]\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]]\n",
      "\n",
      " [[1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  ...\n",
      "  [1.       0.62141  0.093751 ... 0.136937 0.070096 0.032042]\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]]\n",
      "\n",
      " [[1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  [1.       0.504561 0.813233 ... 2.520921 0.771536 0.800058]\n",
      "  ...\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]\n",
      "  [1.       0.040544 0.009582 ... 0.049356 0.027714 0.009525]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  [1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  [1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  ...\n",
      "  [1.       2.22614  1.133739 ... 1.04539  0.773455 0.664235]\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]]\n",
      "\n",
      " [[1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  [1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  [1.       0.838372 0.674698 ... 0.843988 0.431563 0.299334]\n",
      "  ...\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]]\n",
      "\n",
      " [[1.       3.41675  0.580073 ... 0.691625 0.63723  0.542324]\n",
      "  [1.       0.838372 0.674698 ... 0.843988 0.431563 0.299334]\n",
      "  [1.       0.838372 0.674698 ... 0.843988 0.431563 0.299334]\n",
      "  ...\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]\n",
      "  [1.       0.629168 0.326487 ... 0.746906 0.399622 0.161568]\n",
      "  [1.       1.283944 0.686829 ... 0.618664 0.507769 0.265631]]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "dftrain = np.concatenate((dfAwake_train, dfDrowsy_train))\n",
    "dftrainlabels =np.concatenate((dfAwake_trainLabels, dfDrowsy_trainLabels))\n",
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)\n",
    "print(dftrain)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHUFFLING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5659  828 1507 ... 5151 2069 5997]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(dftrainlabels))\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain[idx]\n",
    "dftrainlabels=dftrainlabels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7200, 900, 8)\n",
      "(7200,)\n",
      "[[[1.       2.637889 1.063536 ... 0.768109 0.98261  0.299124]\n",
      "  [1.       2.637889 1.063536 ... 0.768109 0.98261  0.299124]\n",
      "  [1.       1.483053 0.59154  ... 1.272885 0.983053 1.197491]\n",
      "  ...\n",
      "  [1.       0.328997 0.078471 ... 0.098881 0.100894 0.059635]\n",
      "  [1.       0.328997 0.078471 ... 0.098881 0.100894 0.059635]\n",
      "  [1.       1.910039 0.58279  ... 5.292699 1.373207 2.843872]]\n",
      "\n",
      " [[1.       1.466764 0.12034  ... 1.269692 0.404247 0.525883]\n",
      "  [1.       0.148114 0.012538 ... 0.105686 0.025112 0.02285 ]\n",
      "  [1.       0.148114 0.012538 ... 0.105686 0.025112 0.02285 ]\n",
      "  ...\n",
      "  [1.       0.210125 0.080268 ... 0.122757 0.090698 0.022231]\n",
      "  [1.       0.210125 0.080268 ... 0.122757 0.090698 0.022231]\n",
      "  [1.       0.807804 0.154166 ... 0.659684 0.912377 0.871176]]\n",
      "\n",
      " [[1.       1.702923 0.111959 ... 1.139832 0.839774 0.177587]\n",
      "  [1.       1.702923 0.111959 ... 1.139832 0.839774 0.177587]\n",
      "  [1.       1.702923 0.111959 ... 1.139832 0.839774 0.177587]\n",
      "  ...\n",
      "  [1.       0.312068 0.11926  ... 0.037388 0.085647 0.031901]\n",
      "  [1.       0.312068 0.11926  ... 0.037388 0.085647 0.031901]\n",
      "  [1.       0.312068 0.11926  ... 0.037388 0.085647 0.031901]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.       1.908159 0.267834 ... 2.357845 0.73839  0.472265]\n",
      "  [1.       0.430807 0.223776 ... 0.25557  0.114327 0.128549]\n",
      "  [1.       0.430807 0.223776 ... 0.25557  0.114327 0.128549]\n",
      "  ...\n",
      "  [1.       0.936215 0.436401 ... 0.688197 0.255264 0.394662]\n",
      "  [1.       0.936215 0.436401 ... 0.688197 0.255264 0.394662]\n",
      "  [1.       1.059578 0.500458 ... 0.683929 1.310571 0.233349]]\n",
      "\n",
      " [[1.       0.942675 0.826242 ... 1.248089 0.583439 0.601975]\n",
      "  [1.       0.942675 0.826242 ... 1.248089 0.583439 0.601975]\n",
      "  [1.       0.942675 0.826242 ... 1.248089 0.583439 0.601975]\n",
      "  ...\n",
      "  [1.       0.896689 0.36472  ... 0.52643  0.292053 0.292414]\n",
      "  [1.       0.504266 0.648102 ... 0.301428 0.313008 0.127844]\n",
      "  [1.       0.504266 0.648102 ... 0.301428 0.313008 0.127844]]\n",
      "\n",
      " [[1.       0.748653 1.382286 ... 2.312735 0.59951  0.304898]\n",
      "  [1.       1.997132 0.10616  ... 1.012852 0.373712 0.13367 ]\n",
      "  [1.       1.997132 0.10616  ... 1.012852 0.373712 0.13367 ]\n",
      "  ...\n",
      "  [1.       1.831134 0.758944 ... 2.645413 1.576562 1.213706]\n",
      "  [1.       1.831134 0.758944 ... 2.645413 1.576562 1.213706]\n",
      "  [1.       0.273775 0.397325 ... 0.137589 0.134119 0.097907]]]\n",
      "[1. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)\n",
    "print(dftrain)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 900, 8)\n",
      "(3600,)\n",
      "[[[1.       0.059297 0.020334 ... 0.034427 0.027672 0.010734]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  ...\n",
      "  [1.       0.066271 0.031542 ... 0.065743 0.037426 0.029351]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]]\n",
      "\n",
      " [[1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  ...\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]]\n",
      "\n",
      " [[1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  [1.       0.288129 0.058108 ... 0.162441 0.08683  0.028186]\n",
      "  ...\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]\n",
      "  [1.       0.266998 0.129318 ... 0.38657  0.157538 0.060398]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[1.       2.605624 0.15739  ... 0.596198 0.337075 0.20237 ]\n",
      "  [1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  [1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  ...\n",
      "  [1.       0.978712 0.207823 ... 0.464077 0.466472 0.340607]\n",
      "  [1.       0.978712 0.207823 ... 0.464077 0.466472 0.340607]\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]]\n",
      "\n",
      " [[1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  [1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  [1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  ...\n",
      "  [1.       0.978712 0.207823 ... 0.464077 0.466472 0.340607]\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]]\n",
      "\n",
      " [[1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  [1.       1.59252  4.185845 ... 2.112563 0.683071 0.821671]\n",
      "  [1.       1.198376 2.909016 ... 4.854491 2.695061 1.489228]\n",
      "  ...\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]\n",
      "  [1.       0.193527 0.410979 ... 0.499722 0.374073 0.171458]]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "dftest = np.concatenate((dfAwake_test, dfDrowsy_test))\n",
    "dftestlabels =np.concatenate((dfAwake_testLabels, dfDrowsy_testLabels))\n",
    "print(dftest.shape)\n",
    "print(dftestlabels.shape)\n",
    "print(dftest)\n",
    "print(dftestlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3600, 900, 8)\n",
      "(3600,)\n",
      "(7200, 900, 8)\n",
      "(7200,)\n"
     ]
    }
   ],
   "source": [
    "print(dftest.shape)\n",
    "print(dftestlabels.shape)\n",
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftrain shape: (7200, 900, 8)\n",
      "input_shape: 7200\n"
     ]
    }
   ],
   "source": [
    "input_shape = 900*8\n",
    "num_classes = 2\n",
    "# dftrain = dftrain.reshape(dftrain.shape[0],input_shape)\n",
    "print('dftrain shape:', dftrain.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dftrain.astype('float32')\n",
    "dftrainlabels = dftrainlabels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dfttrainlabels shape:  [[0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "dftrainlabels_hot = np_utils.to_categorical(dftrainlabels,num_classes)\n",
    "print('New dfttrainlabels shape: ', dftrainlabels_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dfttrainlabels shape:  (7200, 2)\n",
      "[1. 0. 0. ... 1. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('New dfttrainlabels shape: ', dftrainlabels_hot.shape)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "225/225 [==============================] - 1s 3ms/step - loss: 0.1651 - sparse_categorical_accuracy: 0.9860\n",
      "Test accuracy 0.9859722256660461\n",
      "Test loss 0.16507059335708618\n",
      "225/225 [==============================] - 1s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.97      0.99      3600\n",
      "         1.0       0.97      1.00      0.99      3600\n",
      "\n",
      "    accuracy                           0.99      7200\n",
      "   macro avg       0.99      0.99      0.99      7200\n",
      "weighted avg       0.99      0.99      0.99      7200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model(eegv2).h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(dftrain, dftrainlabels,verbose=1)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)\n",
    "\n",
    "# Print confusion matrix for training data\n",
    "y_pred_train = model.predict(dftrain)\n",
    "# Take the class with the highest probability from the train predictions\n",
    "max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(classification_report(dftrainlabels, max_y_pred_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_m = Sequential()\n",
    "# # Remark: since coreml cannot accept vector shapes of complex shape like\n",
    "# # [80,3] this workaround is used in order to reshape the vector internally\n",
    "# # prior feeding it into the network\n",
    "# model_m.add(Reshape((900, 1), input_shape=(input_shape,)))\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition \n",
    "# model_m.add(Flatten())\n",
    "# model_m.add(Dense(num_classes, activation='softmax'))\n",
    "# print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    # conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    # conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    # conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    # conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    # conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv1)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=dftrain.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FITTING Deep neural network Model in KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks_list = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "#         monitor='val_loss', save_best_only=True),\n",
    "#     keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# model_m.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# # Hyper-parameters\n",
    "# BATCH_SIZE = 400 # V3 changed to 2160\n",
    "# EPOCHS = 50\n",
    "\n",
    "\n",
    "# # Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "# # v1\n",
    "# history = model_m.fit(dftrain,\n",
    "#                       dftrainlabels_hot,\n",
    "#                       batch_size=BATCH_SIZE,\n",
    "#                       epochs=EPOCHS,\n",
    "#                       callbacks=callbacks_list,\n",
    "#                       validation_split=0.2,\n",
    "#                       verbose=1)\n",
    "\n",
    "# # # v1 completing all epochs\n",
    "# # history = model_m.fit(dftrain,\n",
    "# #                       dftrainlabels_hot,\n",
    "# #                       batch_size=BATCH_SIZE,\n",
    "# #                       epochs=EPOCHS,\n",
    "# #                       validation_split=0.2,\n",
    "# #                       verbose=1)\n",
    "\n",
    "# # v3\n",
    "# # history = model_m.fit(dftrain,\n",
    "# #                       dftrainlabels_hot,\n",
    "# #                       batch_size=BATCH_SIZE,\n",
    "# #                       epochs=EPOCHS,\n",
    "# #                       shuffle=True,\n",
    "# #                       validation_split=0.2,\n",
    "# #                       verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "batch_size = 540\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model(eeg).h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=5, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=12, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "history = model.fit(\n",
    "    dftrain,\n",
    "    dftrainlabels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.4,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.plot(history.history['accuracy'], 'r', label='Accuracy of training data')\n",
    "# plt.plot(history.history['val_accuracy'], 'b', label='Accuracy of validation data')\n",
    "# plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "# plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "# plt.title('Model Accuracy and Loss')\n",
    "# plt.ylabel('Accuracy and Loss')\n",
    "# plt.xlabel('Training Epoch')\n",
    "# plt.ylim(0)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Print confusion matrix for training data\n",
    "y_pred_train = model.predict(dftrain)\n",
    "# Take the class with the highest probability from the train predictions\n",
    "max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(classification_report(dftrainlabels, max_y_pred_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set input_shape / reshape for Keras\n",
    "# dftest = dftest.reshape(dftest.shape[0], input_shape)\n",
    "\n",
    "dftest = dftest.astype('float32')\n",
    "dftestlabels = dftestlabels.astype('float32')\n",
    "\n",
    "dftestlabels_hot = np_utils.to_categorical(dftestlabels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dfttrainlabels shape:  [[1. 0.]\n",
      " [1. 0.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [0. 1.]\n",
      " [0. 1.]]\n",
      "New dfttrainlabels shape:  (3600,)\n",
      "New dfttrainlabels shape:  [0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print('New dfttrainlabels shape: ', dftestlabels_hot)\n",
    "print('New dfttrainlabels shape: ', dftestlabels.shape)\n",
    "print('New dfttrainlabels shape: ', dftestlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model_m.evaluate(dftest, dftestlabels_hot, verbose=1)\n",
    "\n",
    "# print('\\nAccuracy on test data: %0.2f' % score[1])\n",
    "# print('\\nLoss on test data: %0.2f' % score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELS = ['Awake','Drowsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = \"sparse_categorical_accuracy\"\n",
    "# plt.figure()\n",
    "# plt.plot(history.history[metric])\n",
    "# plt.plot(history.history[\"val_\" + metric])\n",
    "# plt.title(\"model \" + metric)\n",
    "# plt.ylabel(metric, fontsize=\"large\")\n",
    "# plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "113/113 [==============================] - 0s 3ms/step - loss: 0.3322 - sparse_categorical_accuracy: 0.9167\n",
      "Test accuracy 0.9166666865348816\n",
      "Test loss 0.3322135806083679\n"
     ]
    }
   ],
   "source": [
    "# model = keras.models.load_model(\"best_model(eeg).h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(dftest, dftestlabels,verbose=1)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print confusion matrix for training data\n",
    "# y_pred_train = model.predict(dftest)\n",
    "# # Take the class with the highest probability from the train predictions\n",
    "# max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "# print(classification_report(dftestlabels, max_y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "y_pred_test = model.predict(dftest)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "max_y_test = np.argmax(dftestlabels_hot, axis=1)\n",
    "\n",
    "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
    "\n",
    "print(classification_report(max_y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
