{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODEL FOR PERCLOS NEURAL NET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn import preprocessing\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras.layers import BatchNormalization\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GETTING Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfAwake_train = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostrain_AData.txt', header=None, delim_whitespace=True)\n",
    "dfDrowsy_train = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostrain_DData.txt', header=None, delim_whitespace=True)\n",
    "dfInd_train = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostrain_IData.txt', header=None, delim_whitespace=True)\n",
    "dfAwake_test = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostest_AData.txt', header=None, delim_whitespace=True)\n",
    "dfDrowsy_test = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostest_DData.txt', header=None, delim_whitespace=True)\n",
    "dfInd_test = pd.read_csv('Data/Perclos Data with Indeterminates (90%)/perclostest_IData.txt', header=None, delim_whitespace=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing Retrieved Data informations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2910600, 1)\n",
      "(2430000, 1)\n",
      "(1139400, 1)\n",
      "(810000, 1)\n",
      "(1080000, 1)\n",
      "(1350000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(dfAwake_train.shape)\n",
    "print(dfDrowsy_train.shape)\n",
    "print(dfInd_train.shape)\n",
    "print(dfAwake_test.shape)\n",
    "print(dfDrowsy_test.shape)\n",
    "print(dfInd_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropping Not Needed Columns Keeping PERCLOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfAwake_train = dfAwake_train.drop(dfAwake_train.iloc[:,0:14],axis = 1)\n",
    "# dfDrowsy_train = dfDrowsy_train.drop(dfDrowsy_train.iloc[:,0:14],axis = 1)\n",
    "# dfAwake_test = dfAwake_test.drop(dfAwake_test.iloc[:,0:14],axis = 1)\n",
    "# dfDrowsy_test = dfDrowsy_test.drop(dfDrowsy_test.iloc[:,0:14],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(dfAwake_train.shape)\n",
    "# print(dfDrowsy_train.shape)\n",
    "# print(dfAwake_test.shape)\n",
    "# print(dfDrowsy_test.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESHAPING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3234, 900, 1)\n",
      "(2700, 900, 1)\n",
      "(1266, 900, 1)\n",
      "(900, 900, 1)\n",
      "(1200, 900, 1)\n",
      "(1500, 900, 1)\n"
     ]
    }
   ],
   "source": [
    "dfAwake_train = dfAwake_train.to_numpy()\n",
    "dfDrowsy_train = dfDrowsy_train.to_numpy()\n",
    "dfInd_train = dfInd_train.to_numpy()\n",
    "dfAwake_train = dfAwake_train.reshape(3234,900,1)\n",
    "dfDrowsy_train = dfDrowsy_train.reshape(2700,900,1)\n",
    "dfInd_train = dfInd_train.reshape(1266,900,1)\n",
    "dfAwake_test = dfAwake_test.to_numpy()\n",
    "dfDrowsy_test = dfDrowsy_test.to_numpy()\n",
    "dfInd_test = dfInd_test.to_numpy()\n",
    "dfAwake_test = dfAwake_test.reshape(900,900,1)\n",
    "dfDrowsy_test = dfDrowsy_test.reshape(1200,900,1)\n",
    "dfInd_test = dfInd_test.reshape(1500,900,1)\n",
    "print(dfAwake_train.shape)\n",
    "print(dfDrowsy_train.shape)\n",
    "print(dfInd_train.shape)\n",
    "print(dfAwake_test.shape)\n",
    "print(dfDrowsy_test.shape)\n",
    "print(dfInd_test.shape)\n",
    "# print(dfAwake.head)\n",
    "# print(dfDrowsy.head)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CREATING LABELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3234,)\n",
      "(2700,)\n",
      "(1266,)\n",
      "(900,)\n",
      "(1200,)\n",
      "(1500,)\n"
     ]
    }
   ],
   "source": [
    "dfAwake_trainLabels = np.zeros(3234)\n",
    "print(dfAwake_trainLabels.shape)\n",
    "dfDrowsy_trainLabels = np.ones(2700)\n",
    "print(dfDrowsy_trainLabels.shape)\n",
    "dfInd_trainLabels = np.full(1266,2)\n",
    "print(dfInd_trainLabels.shape)\n",
    "dfAwake_testLabels = np.zeros(900)\n",
    "print(dfAwake_testLabels.shape)\n",
    "dfDrowsy_testLabels = np.ones(1200)\n",
    "print(dfDrowsy_testLabels.shape)\n",
    "dfInd_testLabels = np.full(1500,2)\n",
    "print(dfInd_testLabels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[2 2 2 ... 2 2 2]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[1. 1. 1. ... 1. 1. 1.]\n",
      "[2 2 2 ... 2 2 2]\n"
     ]
    }
   ],
   "source": [
    "print(dfAwake_trainLabels)\n",
    "print(dfDrowsy_trainLabels)\n",
    "print(dfInd_trainLabels)\n",
    "print(dfAwake_testLabels)\n",
    "print(dfDrowsy_testLabels)\n",
    "print(dfInd_testLabels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Awake Data and Drowsy Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5934, 900, 1)\n",
      "(5934,)\n",
      "[[[ 3.666667]\n",
      "  [ 3.666667]\n",
      "  [ 3.666667]\n",
      "  ...\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]]\n",
      "\n",
      " [[ 3.666667]\n",
      "  [ 3.666667]\n",
      "  [ 3.666667]\n",
      "  ...\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]]\n",
      "\n",
      " [[ 3.666667]\n",
      "  [ 3.666667]\n",
      "  [ 3.666667]\n",
      "  ...\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]\n",
      "  [ 3.      ]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[14.333333]\n",
      "  [14.444445]\n",
      "  [14.666666]\n",
      "  ...\n",
      "  [12.666666]\n",
      "  [12.222222]\n",
      "  [12.222222]]\n",
      "\n",
      " [[14.444445]\n",
      "  [14.666666]\n",
      "  [14.666666]\n",
      "  ...\n",
      "  [12.222222]\n",
      "  [12.222222]\n",
      "  [12.555556]]\n",
      "\n",
      " [[14.666666]\n",
      "  [14.666666]\n",
      "  [14.444445]\n",
      "  ...\n",
      "  [12.222222]\n",
      "  [12.555556]\n",
      "  [12.111111]]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# dftrain = np.concatenate((dfAwake_train, dfDrowsy_train, dfInd_train))\n",
    "# dftrainlabels =np.concatenate((dfAwake_trainLabels, dfDrowsy_trainLabels, dfInd_trainLabels))\n",
    "dftrain = np.concatenate((dfAwake_train, dfDrowsy_train))\n",
    "dftrainlabels =np.concatenate((dfAwake_trainLabels, dfDrowsy_trainLabels))\n",
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)\n",
    "print(dftrain)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SHUFFLING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3165 4056 2939 ... 4801 2133 2913]\n"
     ]
    }
   ],
   "source": [
    "idx = np.random.permutation(len(dftrainlabels))\n",
    "print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain=dftrain[idx]\n",
    "dftrainlabels=dftrainlabels[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5934, 900, 1)\n",
      "(5934,)\n",
      "[[[10.111112]\n",
      "  [10.111112]\n",
      "  [10.111112]\n",
      "  ...\n",
      "  [ 8.111111]\n",
      "  [ 8.111111]\n",
      "  [ 8.222222]]\n",
      "\n",
      " [[ 5.444444]\n",
      "  [ 5.444444]\n",
      "  [ 5.111111]\n",
      "  ...\n",
      "  [ 2.333333]\n",
      "  [ 2.333333]\n",
      "  [ 2.333333]]\n",
      "\n",
      " [[ 6.333333]\n",
      "  [ 6.555556]\n",
      "  [ 6.555556]\n",
      "  ...\n",
      "  [ 7.888888]\n",
      "  [ 7.888888]\n",
      "  [ 8.333334]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 9.      ]\n",
      "  [ 9.      ]\n",
      "  [ 8.777778]\n",
      "  ...\n",
      "  [57.888889]\n",
      "  [57.888889]\n",
      "  [57.888889]]\n",
      "\n",
      " [[ 6.555556]\n",
      "  [ 6.555556]\n",
      "  [ 6.555556]\n",
      "  ...\n",
      "  [ 7.111111]\n",
      "  [ 7.333333]\n",
      "  [ 7.333333]]\n",
      "\n",
      " [[ 3.333333]\n",
      "  [ 3.333333]\n",
      "  [ 3.333333]\n",
      "  ...\n",
      "  [ 4.      ]\n",
      "  [ 3.777778]\n",
      "  [ 3.777778]]]\n",
      "[0. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)\n",
    "print(dftrain)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 900, 1)\n",
      "(2100,)\n",
      "[[[0.777778]\n",
      "  [0.777778]\n",
      "  [0.777778]\n",
      "  ...\n",
      "  [1.666667]\n",
      "  [1.666667]\n",
      "  [1.666667]]\n",
      "\n",
      " [[0.777778]\n",
      "  [0.777778]\n",
      "  [0.777778]\n",
      "  ...\n",
      "  [1.666667]\n",
      "  [1.666667]\n",
      "  [1.666667]]\n",
      "\n",
      " [[0.777778]\n",
      "  [0.777778]\n",
      "  [0.777778]\n",
      "  ...\n",
      "  [1.666667]\n",
      "  [1.666667]\n",
      "  [1.666667]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[5.444444]\n",
      "  [5.444444]\n",
      "  [5.444444]\n",
      "  ...\n",
      "  [6.666667]\n",
      "  [6.666667]\n",
      "  [6.666667]]\n",
      "\n",
      " [[5.444444]\n",
      "  [5.444444]\n",
      "  [5.666667]\n",
      "  ...\n",
      "  [6.666667]\n",
      "  [6.666667]\n",
      "  [6.666667]]\n",
      "\n",
      " [[5.444444]\n",
      "  [5.666667]\n",
      "  [5.777778]\n",
      "  ...\n",
      "  [6.666667]\n",
      "  [6.666667]\n",
      "  [6.666667]]]\n",
      "[0. 0. 0. ... 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# dftest = np.concatenate((dfAwake_test, dfDrowsy_test,dfInd_test))\n",
    "# dftestlabels =np.concatenate((dfAwake_testLabels, dfDrowsy_testLabels,dfInd_testLabels))\n",
    "dftest = np.concatenate((dfAwake_test, dfDrowsy_test))\n",
    "dftestlabels =np.concatenate((dfAwake_testLabels, dfDrowsy_testLabels))\n",
    "print(dftest.shape)\n",
    "print(dftestlabels.shape)\n",
    "print(dftest)\n",
    "print(dftestlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2100, 900, 1)\n",
      "(2100,)\n",
      "(5934, 900, 1)\n",
      "(5934,)\n"
     ]
    }
   ],
   "source": [
    "print(dftest.shape)\n",
    "print(dftestlabels.shape)\n",
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set input and output dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dftrain shape: (5934, 900, 1)\n",
      "input_shape: 900\n"
     ]
    }
   ],
   "source": [
    "input_shape = 900\n",
    "# num_classes = 3\n",
    "num_classes = 2\n",
    "# dftrain = dftrain.reshape(dftrain.shape[0],input_shape)\n",
    "print('dftrain shape:', dftrain.shape)\n",
    "print('input_shape:', input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dftrain = dftrain.astype('float32')\n",
    "dftrainlabels = dftrainlabels.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dfttrainlabels shape:  [[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " ...\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "dftrainlabels_hot = np_utils.to_categorical(dftrainlabels,num_classes)\n",
    "print('New dfttrainlabels shape: ', dftrainlabels_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New dfttrainlabels shape:  (5934, 2)\n",
      "[0. 1. 0. ... 1. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "print('New dfttrainlabels shape: ', dftrainlabels_hot.shape)\n",
    "print(dftrainlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5934, 900, 1)\n",
      "(5934,)\n"
     ]
    }
   ],
   "source": [
    "print(dftrain.shape)\n",
    "print(dftrainlabels.shape)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "186/186 [==============================] - 1s 3ms/step - loss: 0.3426 - sparse_categorical_accuracy: 0.8000\n",
      "Test accuracy 0.7999662756919861\n",
      "Test loss 0.34261301159858704\n"
     ]
    }
   ],
   "source": [
    "model = keras.models.load_model(\"best_model(perclosv2).h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(dftrain, dftrainlabels,verbose=1)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_m = Sequential()\n",
    "# # Remark: since coreml cannot accept vector shapes of complex shape like\n",
    "# # [80,3] this workaround is used in order to reshape the vector internally\n",
    "# # prior feeding it into the network\n",
    "# model_m.add(Reshape((900, 1), input_shape=(input_shape,)))\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition\n",
    "# model_m.add(Dense(100, activation='relu'))\n",
    "# # model_m.add(BatchNormalization()) # V2 addition \n",
    "# model_m.add(Flatten())\n",
    "# model_m.add(Dense(num_classes, activation='softmax'))\n",
    "# print(model_m.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "    conv1 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(input_layer)\n",
    "    conv1 = keras.layers.BatchNormalization()(conv1)\n",
    "    conv1 = keras.layers.ReLU()(conv1)\n",
    "\n",
    "    # conv2 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv1)\n",
    "    # conv2 = keras.layers.BatchNormalization()(conv2)\n",
    "    # conv2 = keras.layers.ReLU()(conv2)\n",
    "\n",
    "    # conv3 = keras.layers.Conv1D(filters=64, kernel_size=3, padding=\"same\")(conv2)\n",
    "    # conv3 = keras.layers.BatchNormalization()(conv3)\n",
    "    # conv3 = keras.layers.ReLU()(conv3)\n",
    "\n",
    "    gap = keras.layers.GlobalAveragePooling1D()(conv1)\n",
    "\n",
    "    output_layer = keras.layers.Dense(num_classes, activation=\"softmax\")(gap)\n",
    "\n",
    "    return keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "\n",
    "model = make_model(input_shape=dftrain.shape[1:])\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FITTING Deep neural network Model in KERAS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks_list = [\n",
    "#     keras.callbacks.ModelCheckpoint(\n",
    "#         filepath='best_model.{epoch:02d}-{val_loss:.2f}.h5',\n",
    "#         monitor='val_loss', save_best_only=True),\n",
    "#     keras.callbacks.EarlyStopping(monitor='accuracy', patience=1)\n",
    "# ]\n",
    "\n",
    "\n",
    "\n",
    "# model_m.compile(loss='categorical_crossentropy',\n",
    "#                 optimizer=Adam(learning_rate=0.001), metrics=['accuracy'])\n",
    "\n",
    "# # Hyper-parameters\n",
    "# BATCH_SIZE = 400 # V3 changed to 2160\n",
    "# EPOCHS = 50\n",
    "\n",
    "\n",
    "# # Enable validation to use ModelCheckpoint and EarlyStopping callbacks.\n",
    "# # v1\n",
    "# history = model_m.fit(dftrain,\n",
    "#                       dftrainlabels_hot,\n",
    "#                       batch_size=BATCH_SIZE,\n",
    "#                       epochs=EPOCHS,\n",
    "#                       callbacks=callbacks_list,\n",
    "#                       validation_split=0.2,\n",
    "#                       verbose=1)\n",
    "\n",
    "# # # v1 completing all epochs\n",
    "# # history = model_m.fit(dftrain,\n",
    "# #                       dftrainlabels_hot,\n",
    "# #                       batch_size=BATCH_SIZE,\n",
    "# #                       epochs=EPOCHS,\n",
    "# #                       validation_split=0.2,\n",
    "# #                       verbose=1)\n",
    "\n",
    "# # v3\n",
    "# # history = model_m.fit(dftrain,\n",
    "# #                       dftrainlabels_hot,\n",
    "# #                       batch_size=BATCH_SIZE,\n",
    "# #                       epochs=EPOCHS,\n",
    "# #                       shuffle=True,\n",
    "# #                       validation_split=0.2,\n",
    "# #                       verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 250\n",
    "batch_size = 45\n",
    "\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        \"best_model(perclos).h5\", save_best_only=True, monitor=\"val_loss\"\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.5, patience=10, min_lr=0.0001\n",
    "    ),\n",
    "    keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=25, verbose=1),\n",
    "]\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    metrics=[\"sparse_categorical_accuracy\"],\n",
    ")\n",
    "# model.compile(\n",
    "#     optimizer=\"adam\",\n",
    "#     loss=\"categorical_crossentropy\",\n",
    "#     metrics=[\"accuracy\"],\n",
    "# )\n",
    "history = model.fit(\n",
    "    dftrain,\n",
    "    dftrainlabels,\n",
    "    batch_size=batch_size,\n",
    "    epochs=epochs,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=0.2,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(6, 4))\n",
    "# plt.plot(history.history['accuracy'], 'r', label='Accuracy of training data')\n",
    "# plt.plot(history.history['val_accuracy'], 'b', label='Accuracy of validation data')\n",
    "# plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "# plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "# plt.title('Model Accuracy and Loss')\n",
    "# plt.ylabel('Accuracy and Loss')\n",
    "# plt.xlabel('Training Epoch')\n",
    "# plt.ylim(0)\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "metric = \"sparse_categorical_accuracy\"\n",
    "plt.figure()\n",
    "plt.plot(history.history[metric])\n",
    "plt.plot(history.history[\"val_\" + metric])\n",
    "plt.plot(history.history['loss'], 'r--', label='Loss of training data')\n",
    "plt.plot(history.history['val_loss'], 'b--', label='Loss of validation data')\n",
    "plt.title(\"model \" + metric)\n",
    "plt.ylabel(metric, fontsize=\"large\")\n",
    "plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "plt.legend([\"train\", \"val\",\"loss\",\"val_loss\"], loc=\"best\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "plt.show()\n",
    "plt.close()\n",
    "\n",
    "# Print confusion matrix for training data\n",
    "y_pred_train = model.predict(dftrain)\n",
    "# Take the class with the highest probability from the train predictions\n",
    "max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "print(classification_report(dftrainlabels, max_y_pred_train))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking against Testing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Set input_shape / reshape for Keras\n",
    "# dftest = dftest.reshape(dftest.shape[0], input_shape)\n",
    "\n",
    "dftest = dftest.astype('float32')\n",
    "dftestlabels = dftestlabels.astype('float32')\n",
    "\n",
    "dftestlabels_hot = np_utils.to_categorical(dftestlabels, num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('New dfttrainlabels shape: ', dftestlabels_hot)\n",
    "print('New dfttrainlabels shape: ', dftestlabels.shape)\n",
    "print('New dfttrainlabels shape: ', dftestlabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# score = model_m.evaluate(dftest, dftestlabels_hot, verbose=1)\n",
    "\n",
    "# print('\\nAccuracy on test data: %0.2f' % score[1])\n",
    "# print('\\nLoss on test data: %0.2f' % score[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABELS = ['Awake','Drowsy','Indeterminate']\n",
    "LABELS = ['Awake','Drowsy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# metric = \"sparse_categorical_accuracy\"\n",
    "# plt.figure()\n",
    "# plt.plot(history.history[metric])\n",
    "# plt.plot(history.history[\"val_\" + metric])\n",
    "# plt.title(\"model \" + metric)\n",
    "# plt.ylabel(metric, fontsize=\"large\")\n",
    "# plt.xlabel(\"epoch\", fontsize=\"large\")\n",
    "# plt.legend([\"train\", \"val\"], loc=\"best\")\n",
    "# plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.load_model(\"best_model(perclosv2).h5\")\n",
    "\n",
    "test_loss, test_acc = model.evaluate(dftest, dftestlabels,verbose=1)\n",
    "\n",
    "print(\"Test accuracy\", test_acc)\n",
    "print(\"Test loss\", test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Print confusion matrix for training data\n",
    "# y_pred_train = model.predict(dftest)\n",
    "# # Take the class with the highest probability from the train predictions\n",
    "# max_y_pred_train = np.argmax(y_pred_train, axis=1)\n",
    "# print(classification_report(dftestlabels, max_y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_confusion_matrix(validations, predictions):\n",
    "\n",
    "    matrix = metrics.confusion_matrix(validations, predictions)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.heatmap(matrix,\n",
    "                cmap='coolwarm',\n",
    "                linecolor='white',\n",
    "                linewidths=1,\n",
    "                xticklabels=LABELS,\n",
    "                yticklabels=LABELS,\n",
    "                annot=True,\n",
    "                fmt='d')\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.show()\n",
    "\n",
    "y_pred_test = model.predict(dftest)\n",
    "# Take the class with the highest probability from the test predictions\n",
    "max_y_pred_test = np.argmax(y_pred_test, axis=1)\n",
    "max_y_test = np.argmax(dftestlabels_hot, axis=1)\n",
    "\n",
    "show_confusion_matrix(max_y_test, max_y_pred_test)\n",
    "\n",
    "print(classification_report(max_y_test, max_y_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = keras.models.load_model(\"best_model.h5\")\n",
    "# print(model.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
